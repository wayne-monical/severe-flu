---
title: 'Predicting Severe Flu from Clinical and Demographic Covariates'
author: "Wayne Monical"
date: "2025-05-05"
output: github_document
---




```{r Libraries, warning=FALSE, message=FALSE}
library(caret)
library(tidyverse)
library(vtable)
library(corrplot)
library(vip)
library(patchwork)
library(pROC)
```

```{r Data_Load}
flu = 
  read_csv('severe_flu.csv', show_col_types = FALSE) |> 
  select(-id) |> 
  mutate(
    gender = factor(ifelse(gender, 'Male', 'Female')),
    race = factor(race, levels = 1:4,labels = c("White", "Asian", "Black", "Hispanic")),
    smoking = factor(smoking, levels = 0:2, labels = c('Never_Smoked', 'Former_Smoker', 'Current_Smoker')),
    diabetes = factor(diabetes, levels = 0:1, labels = c('Not_Present', 'Present')),
    hypertension = factor(hypertension, levels = 0:1, labels = c('Not_Present', 'Present')),
    severe_flu = factor(severe_flu, levels = 0:1, labels = c('Not_Present', 'Present'))
  )
```


# Introduction

The goal of this report is to evaluate the relationship between attributes and the risk of severe flu in the six-month period following vaccinations. This report uses a data set containing one-thousand observations, each from a unique individual. The variable of interest in the data set is the presence of a case of severe flu in the six-month period following vaccination. Of the one-thousand patients, two-hundred and fifty-three of the patients experienced severe flu. The data set contains eleven demographic, clinical, and lifestyle covariates associated with each patient, namely age, gender, race, smoking status, height, weight, BMI, the presence of diabetes and hypertension, systolic blood pressure (SBP), and a measure of low-density lipoprotein (LDL). In order to explore the relationship between demographic and clinical factors, several machine learning models were trained. The logistic regression model with elastic net penalty was selected as the final model. It is a highly interpretable model, and it may be used to infer the relationship between the demographic factors and the risk of developing severe flu. 

# Exploratory Analysis

There are no missing values in the data set. The summary statistics and relationship plots for the discrete and continuous variables are given in the tables below. The strongest associations are between BMI, height, and weight. This follows from our previous understanding that BMI is calculated based on height and weight. The three-way association between age, SBP, and LDL aligns with the understanding that older patients are more at risk of cardiac health problems. We observe differences in the incidence of severe flu in diabetes, hypertension, BMI, and weight, and a smaller difference in LDL. 


```{r Data_Cleaning, include=FALSE, eval=FALSE}
# check for uniqueness
max(table(flu$id))

# check for missing data 
sum(is.na(flu))
```

### Summary Statistics
```{r Summary_Stats}
sumtable(flu, out = 'kable')
```




### Plotting Discrete Variables
```{r}
discrete_cols = c('gender', 'race', 'smoking', 'diabetes', 'hypertension')
numeric_cols = c('age', 'height', 'weight', 'bmi', 'SBP', 'LDL')

flu |> 
  select(-numeric_cols) |> 
  pivot_longer(cols = discrete_cols, names_to = "Variable", values_to = "Value") |> 
  group_by(severe_flu, Variable, Value) |> 
  summarise(n = n(), .groups = "drop_last") |>
  mutate(Proportion = n / sum(n)) |>
  ggplot(aes(x = severe_flu, y = Proportion, fill = Value))+
  geom_bar(stat = 'identity', position = "dodge" )+
  facet_wrap(~ Variable, scales = "free_y") +
  labs(title = 'Severe Flu versus Continuous Variables') +
  xlab('Presence of Severe Flu') + 
  ylab('')+
  theme(legend.position = "none")
```



### Plotting Continuous Variables
```{r}
flu |> 
  pivot_longer(cols = numeric_cols, names_to = "Variable", values_to = "Value") |> 
  ggplot(aes(x = severe_flu, y = Value)) +
  geom_boxplot() +
  facet_wrap(~ Variable, scales = "free_y") +
  labs(title = 'Severe Flu versus Continuous Variables') +
  xlab('Presence of Severe Flu') + 
  ylab('')
```

### Plotting Correlation
```{r}
continuous = flu[,names(flu)[sapply(flu, is.numeric)]]
correlations = cor(continuous)
corrplot(correlations)
```



# Methods
The data was randomly split into training and testing sets for model building. A cross-validated resampling approach was used to tune the hyperparameters and test the model on unseen data. The hyperparameters were chosen to maximize the modelsâ€™ accuracy. While this measure may bias training towards the majority class (no severe flu) over other considered metrics such as AUC ROC, the measure of accuracy is highly interpretable, and therefore applicable to this study. Logistic regression, penalized logistic regression, support vector machines, and tree-based models were trained on the data. The models were evaluated by their average accuracy of the cross-validated resamplings. The selected model was then evaluated on the test set to get an unbiased evaluation of its performance. 
Logistic Regression
An unpenalized logistic regression model was trained on the data in order to establish an initial estimate of linear effects. The reference categories are white for race, female for gender, never smoked for smoking status, and the absence of diabetes or hypertension. In order to improve the model on unseen data, an elastic penalty was applied. The continuous data (age, height, weight, BMI, SBP, and LDL), was scaled so that the same penalty applied to each variable. The discrete variables were not scaled in order to preserve their interpretability. In order to test the interaction effects of the variables, another logistic regression with an elastic penalty on all second order interaction effects was also tested. 
Advanced Models
Support vector machine models were trained with one linear and one radial kernel. The linear SVM was tested for performance on costs 0.01, 0.1, 1, 5, 10, and 15. The radial kernel SVM was tested for performance on sigma values 0.01, 0.05, and 0.1 and costs of 0.1, 1, and 10. The random forest model was tested with tree depths ranging from 2 to 7 and minimum node sizes ranging from 2 to 6. The boosted random forest model was trained with possible tree values of 25, 50, 75, 100, and 150, interaction depth of 1, 2, and 3, a shrinkage value of 0.01, 0.03, or 0.06, and a minimum  node size of 5 or 10. 
Results
Logistic Regression
The coefficients for the three logistic regression models (unpenalized, elastic net penalty, and elastic net penalty with interaction) are given below.  The penalized logistic regression model, the optimal hyperparameters for alpha and lambda were found to be 1.0 and 0.00241, respectively. Many variables, such as former smoker and weight, are dropped from the penalized model. Height, originally associated with an increase in the risk of severe flu, is associated with a decrease in the risk of severe flu after the penalty is applied. BMI plays a significant role in all three models. It is the single largest variable coefficient in the first two models, and it is present in four of the interaction terms in the interactions model.

Table 3: Logistic Regression Coefficients


Table 4: Penalized logistic Regression Coefficients with Second Order Interaction




Figure 2: Logistic Regression with Elastic Net Penalty 

Figure 3: Logistic Regression with Elastic Net and Second Order Interaction

Support Vector Machines
The optimal cost for the linear support vector machine was found to be equal to 0.01. The optimal cost for the radial support vector machine was found to be equal to 0.1 with a sigma value of 0.01. Below is the SVM decision boundary linear and radial kernel for a Hispanic man, a current smoker, with diabetes and hypertension. The linear kernel has a straight decision boundary, while the radial kernel may have a curved decision boundary. The linear and radial SVMs achieved a training accuracy of 0.766 and 0.765 respectively. 

Figure 4: Linear SVM 


Figure 5: Radial SVM 

Tree-Based Methods
The random forest model achieved a cross-validated accuracy of 0.773. BMI, height, and hypertension were identified as the most relevant factors in the model by the variable importance plot. However, when the model was boosted, the clinical measures of LDL and SBP became significantly more important. The boosted random forest model achieved a cross-validated accuracy of 0.776, slightly improving the original model.

Figure 6: Random Forest Model Training and Variable Importance


Figure 7: Boosted Random Forest Model Training and Variable Importance

Model Comparison
The models performed similarly on the training set, each within the range of less than two percent accuracy. The elastic net achieved the highest average cross validated accuracy by one percentage point. Other models, such as the elastic net with interaction and the linear SVM offer a more consistent average, since they achieved a lower standard deviation of accuracy scores during model training. Evaluating the selected model, the elastic net, on the test set, it achieves an accuracy of 0.733, which is lower than training. 

Table 5: Model Comparison on Test Set


Figure 8: Model Accuracy Comparison on Training Set

Table: Elastic Net Model Test Set Confusion Matrix 



Figure 9: Elastic Net ROC Curve on Test Set

Conclusion
I recommend that the researchers use the logistic regression model with elastic net penalty. The boosted random forest and support vector machine models do not provide better predictive power than the simpler, more interpretable elastic net, and they perform worse during cross validation. In order to create a risk score, the researchers may apply the logistic regression model to new data to obtain the estimated probability of developing severe flu in the six-month period after vaccination. This value will fall between zero and one, with a low value corresponding to low risk for severe flu, and a higher score corresponding to elevated risk. The key demographic and clinical factors that predicted risk of severe flu were BMI, LDL, and SBP, as identified by the variable importance plots of the random forest models and the penalized logistic regression model. 











### Data Scaling

```{r}
# create model matrix
x = model.matrix(severe_flu ~ . , data = flu)
x = x[,2:ncol(x)] # drop intercept

# only scale the numeric cols
is_binary = apply(x, 2, function(col) all(col %in% c(0, 1)))
x[, !is_binary] = scale(x[, !is_binary])


# create model matrix with interactions
x_int = model.matrix(severe_flu ~ .^2 , data = flu)
x_int = x_int[,2:ncol(x_int)] # drop intercept
is_binary = apply(x_int, 2, function(col) all(col %in% c(0, 1)))
x_int[, !is_binary] = scale(x_int[, !is_binary])
```



### Test/Train Split

```{r}
# sample for test/train split
set.seed(1)
test_set_index = sample(1:nrow(flu), size = round(0.7 * nrow(flu)), replace = FALSE)

x_train = x[test_set_index,]
y_train = flu$severe_flu[test_set_index]

x_test = x[-test_set_index,]
y_test = flu$severe_flu[-test_set_index]

# split data set with interactions
x_train_interaction = x_int[test_set_index,]
x_test_interaction =  x_int[-test_set_index,]
```




### Cross Validation 

Five fold cross validaiton conducted five times (five different data partitions)
```{r}
# set up cross validation control
ctrl = 
  trainControl(
    method = "repeatedcv", 
    repeats = 5,
    number = 5,
    summaryFunction = defaultSummary,
    classProbs = TRUE)
```

## Logistic Regression 

Basic Model
```{r}
flu.logistic_regression =
  train(x = x_train,
        y = y_train,
        method = "glm", 
        metric = 'Accuracy',
        trControl = ctrl)

summary(flu.logistic_regression$finalModel)
```
Coefficients
```{r}
data.frame(
  name = names(flu.logistic_regression$finalModel$coefficients),
  value = round(flu.logistic_regression$finalModel$coefficients, 3)) |> 
  knitr::kable()
```




### Penalized Logistic Regression

```{r}
# train elastic net model
set.seed(1)
flu.elastic_net =
  train(x = x_train,
        y = y_train,
        method = "glmnet", 
        metric = 'Accuracy',
        trControl = ctrl)

# print the coefficients of the best model
coef = coef(flu.elastic_net$finalModel,
     s = flu.elastic_net$bestTune$lambda) 

coef
```

```{r}
data.frame(
  name = row.names(coef),
  val = round(coef[,'s1'], 3)
) |> 
  knitr::kable()
```

Training error
```{r}
print(mean(flu.elastic_net$resample$Accuracy))
```

```{r}
flu.elastic_net$bestTune
```


```{r}
plot(flu.elastic_net)
```


```{r}
plot(flu.elastic_net$finalModel)
```

## Elastic Net with Interaction

```{r}
# train elastic net model
set.seed(2)
flu.elastic_net_interaction =
  train(x = x_train_interaction,
        y = y_train,
        method = "glmnet", 
        metric = 'Accuracy',
        trControl = ctrl)
```

```{r}
# print the non-zero coefficients of the best model
coeffs = 
  coef(flu.elastic_net_interaction$finalModel,
     s = flu.elastic_net_interaction$bestTune$lambda)

coeff_names = row.names(coeffs)
coeff_vals = coeffs[,'s1']
names(coeff_vals) = coeff_names

# non zero coeffs 
coeffs_non_zero = coeff_names[coeff_vals > 0]
coeffs_non_zero = coeffs_non_zero[2:length(coeffs_non_zero)] # drop intercept

data.frame(
  name = coeffs_non_zero,
  value =  round(coeff_vals[coeffs_non_zero], 3)) |> 
  arrange(-value) |> 
  knitr::kable()
```
Training error

```{r}
print(mean(flu.elastic_net_interaction$resample$Accuracy))
```


```{r}
plot(flu.elastic_net_interaction$finalModel)
```

```{r}
plot(flu.elastic_net_interaction)
```

```{r}
flu.elastic_net_interaction$bestTune
```


## SVM

### Linear SVM

```{r}
# train elastic net model with kernlab package
set.seed(3)
flu.linear_svm =
  train(x = x_train,
        y = y_train,
        method = "svmLinear",
        # tuneLength = seq(0.1, 5, len = 10),
        tuneGrid = expand.grid(C = c(0.01, 0.1, 1, 5, 10, 15)),
        preProc = c("center", "scale"),
        metric = 'Accuracy',
        trControl = ctrl,
        verbose = FALSE)
```


```{r}
flu.linear_svm$bestTune
```


```{r}
print(mean(flu.linear_svm$resample$Accuracy))
```


### Plotting Linear SVM Decision Boundary
```{r}
args_list =
  x_train |> 
  colMeans() |> 
  as.list()

args_list$bmi = seq(min(x_train[,'bmi']), max(x_train[,'bmi']), length = 100)
args_list$LDL = seq(min(x_train[,'LDL']), max(x_train[,'LDL']), length = 100)
args_list$genderMale = 1
args_list$smokingCurrent_Smoker = 1
args_list$diabetesPresent = 1
args_list$hypertensionPresent = 1
args_list$raceHispanic = 1
args_list$SBP = 10
args_list$age = 3

  
grid = do.call(expand.grid, args_list)

# Predict on the grid
grid$Pred <- predict(flu.linear_svm, newdata = grid)

# Plot decision boundary
x_train |> 
  as.data.frame() |> 
  mutate(severe_flu = y_train) |> 
  ggplot(aes(x = bmi, y = LDL)) +
  geom_point(aes(color = severe_flu)) +
  geom_tile(data = grid, aes(x = bmi, y = LDL, fill= Pred), alpha = 0.2) +
  labs(title = "Linear SVM Decision Boundary") +
  theme_minimal()
```


```{r}
plot(flu.linear_svm)
```


```{r}
flu.linear_svm$bestTune
```



### SVM with Radial Kernel

```{r}
# train elastic net model with kernlab package
set.seed(4)
flu.radial_svm =
  train(x = x_train,
        y = y_train,
        method = "svmRadial",
        tuneGrid = expand.grid(
          sigma = c(0.01, 0.05, 0.1),
          C = c(0.1, 1, 10)),
        preProc = c("center", "scale"),
        metric = 'Accuracy',
        trControl = ctrl)
```

```{r}
flu.radial_svm$bestTune
```


Radial SVM Training Accuracy
```{r}
print(mean(flu.radial_svm$resample$Accuracy))
```


### Plotting Radial Kernel 
```{r}
args_list =
  x_train |> 
  colMeans() |> 
  as.list()

args_list$bmi = seq(min(x_train[,'bmi']), max(x_train[,'bmi']), length = 100)
args_list$LDL = seq(min(x_train[,'LDL']), max(x_train[,'LDL']), length = 100)
args_list$smokingCurrent_Smoker = 1
args_list$diabetesPresent = 1
args_list$hypertensionPresent = 1
args_list$raceHispanic = 1
args_list$genderMale = 1

grid = do.call(expand.grid, args_list)

# Predict on the grid
grid$Pred <- predict(flu.radial_svm, newdata = grid)

# Plot decision boundary
x_train |> 
  as.data.frame() |> 
  mutate(severe_flu = y_train) |> 
  ggplot(aes(x = bmi, y = LDL)) +
  geom_point(aes(color = severe_flu)) +
  geom_tile(data = grid, aes(x = bmi, y = LDL, fill= Pred), alpha = 0.2) +
  labs(title = "Radial SVM Decision Boundary") +
  theme_minimal()
```

```{r}
plot(flu.radial_svm)
```




## Tree-Based Methods

### Random Forest

Below I train a random forest to predict out of state tuition. I plot the importance of each variable in the data set and find that the `Expend` variable, the instruction expenditure per student, is the most important variable for predicting `Outstate`, the variable of interest. I report that the test error for this model is equal to 1553.659, as measured by RMSE. 
```{r}
rf.grid <- expand.grid(mtry = 1:7,
                       splitrule = 'extratrees',
                       min.node.size = 2:6)
set.seed(5)
flu.rf =
  train(
    x = x_train,
    y = y_train,
    method = "ranger",
    tuneGrid = rf.grid,
    metric = 'Accuracy',
    importance = 'permutation',
    trControl = ctrl)

ggplot(flu.rf, highlight = TRUE)+
  labs(title = "Random Forest Model Training")
```

```{r}
print(mean(flu.rf$resample$Accuracy))
hist(flu.rf$resample$Accuracy)
```

```{r}
flu.rf$bestTune
```



### Plotting Variable Importance 

```{r}
flu_feature_importance = ranger::importance(flu.rf$finalModel)

data.frame(
  feature = names(flu_feature_importance),
  importance = flu_feature_importance) |> 
  ggplot(aes(x = reorder(feature, -importance), y = importance)) +
  geom_bar(stat = "identity")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  labs(title = 'Variable Importance Plot of Random Forest')+
  xlab('Features')+
  ylab('Relative Importance')
```



### Boosting the Random Forest

Below I apply the boosting algorithm to the random forest, using the previous model as a starting point. Again, I plot the importance of each variable, and find again that per student expendicture is the most powerful predictor in the model, again followed by room and board cost. I report the test error of this model to be 1497.826 as measured by RMSE, a slight improvement over the previous model. 

```{r}
gbm.grid = 
  expand.grid(
    n.trees = c(25, 50, 75, 100, 150),
    interaction.depth = 1:3,
    shrinkage = c(0.01, 0.03, 0.06),
    n.minobsinnode = c(5, 10))

set.seed(6)
flu.gbm =
  train(
    x = x_train,
    y = y_train,
    method = "gbm",
    tuneGrid = gbm.grid,
    trControl = ctrl,
    metric = 'Accuracy',
    verbose = FALSE 
  )

ggplot(flu.gbm, highlight = TRUE)+
  labs(title = 'Boosted Random Forest Model Training')
```



### Report Variable Importance
```{r}
flu.gmb.summary = summary(flu.gbm)

flu.gmb.summary |> 
  ggplot(aes(x = reorder(var, -rel.inf), y = rel.inf)) + 
  geom_bar(stat = "identity")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  labs(title = 'Variable Importance Plot of Boosted Random Forest')+
  xlab('Features')+
  ylab('Relative Importance')
```


### Comparing Models

```{r}

# aggregating models
model.Accuracy= 
  rbind(
  data.frame(
    model = 'Elastic Net',
    Accuracy = flu.elastic_net$resample$Accuracy),
  data.frame(
    model = 'Elastic Net with Interaction',
    Accuracy = flu.elastic_net_interaction$resample$Accuracy),
  data.frame(
    model = 'Linear SVM',
    Accuracy = flu.linear_svm$resample$Accuracy
  ),
  data.frame(
    model = 'Radial SVM',
    Accuracy = flu.radial_svm$resample$Accuracy
  ),
  data.frame(
    model = 'Random Forest',
    Accuracy = flu.rf$resample$Accuracy
  ),
    data.frame(
    model = 'Boosted Random Forest',
    Accuracy = flu.gbm$resample$Accuracy
  )
)

# average Accuracy
model.Accuracy %>% 
  group_by(model) %>% 
  summarize(
    round(mean(Accuracy), 3),
    round(sd(Accuracy), 3)) %>% 
  knitr::kable(col.names = c('Model', 'Mean CV Accuracy', 'SD CV Accuracy'))
```

Plotting the models' Accuracy scores. 
```{r}
model.Accuracy |>
  ggplot(aes(x = model, y = Accuracy)) +
  geom_violin()+
  stat_summary(
    fun = "mean",
               geom = "point",
               color = "red")+
  labs(title = "Model Accuracy Comparison", xlab = "Model")+ 
  theme(axis.text.x = element_text(angle = 35, vjust = 0.95, hjust=1))
```


## Test Set Evaluation

```{r}
preds = predict(flu.elastic_net, x_test_interaction)

confusionMatrix(preds, reference = y_test)
```


### ROC Curve
```{r}
roc_obj <- roc(response = as.numeric(y_test), predictor = as.numeric(preds))
plot(roc_obj, col = "blue", print.auc = TRUE)
```



